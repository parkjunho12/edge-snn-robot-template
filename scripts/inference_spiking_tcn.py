"""
inference_spiking_tcn.py

SpikingTCN ë°°í¬ìš© ì¶”ë¡  ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸

ì „ì œ:
  ./output/<encoding_type>/ ì•ˆì— ë‹¤ìŒ 4ê°œ ì•„í‹°íŒ©íŠ¸ê°€ ì¡´ì¬í•œë‹¤ê³  ê°€ì •
    - spiking_tcn_<encoding_type>_best.pth
    - emg_scaler.pkl
    - label_encoder.pkl
    - emg_meta.json

ì‚¬ìš© ì˜ˆ:
  1) ë”ë¯¸ EMG ìœˆë„ìš°ë¡œ í…ŒìŠ¤íŠ¸
      python inference_spiking_tcn.py --artifact-dir ./output/latency

  2) ì§ì ‘ ìˆ˜ì§‘í•œ EMG ìœˆë„ìš° (numpy .npy íŒŒì¼)
      # np.save("emg_window.npy", emg_window)  # shape: [window_size, num_channels]
      python inference_spiking_tcn.py \
        --artifact-dir ./output/latency \
        --emg-npy ./emg_window.npy
"""

import argparse
import json
from pathlib import Path

import joblib
import numpy as np
import torch
import torch.nn as nn

from src.models.spiking_tcn import SpikingTCN

from src.emg_io.data_src.ninapro import (
    load_ninapro_data,
    preprocess_data_for_networks,
)


# ğŸ”§ SpikingTCN í•˜ì´í¼íŒŒë¼ë¯¸í„° (í›ˆë ¨ ë•Œì™€ ë™ì¼í•´ì•¼ í•¨!)
#   â†’ í•„ìš”í•˜ë©´ emg_meta.jsonì— ê°™ì´ ì €ì¥í•˜ë„ë¡ ë‚˜ì¤‘ì— í™•ì¥ ê°€ëŠ¥
SPIKING_TCN_CHANNELS = [64, 128, 256]
SPIKING_TCN_KERNEL_SIZE = 3
SPIKING_TCN_DROPOUT = 0.2
SPIKING_TCN_BETA = 0.94
SPIKING_TCN_V_TH = 1.0


def load_artifacts(artifact_dir: Path):
    """ë°°í¬ìš© ì•„í‹°íŒ©íŠ¸ 4ê°œ ë¡œë“œ"""
    artifact_dir = Path(artifact_dir)

    # 1) ë©”íƒ€ ì •ë³´
    meta_path = artifact_dir / "emg_meta.json"
    with meta_path.open("r", encoding="utf-8") as f:
        emg_meta = json.load(f)

    # 2) ìŠ¤ì¼€ì¼ëŸ¬
    scaler_path = artifact_dir / "emg_scaler.pkl"
    scaler = joblib.load(scaler_path)

    # 3) LabelEncoder
    label_encoder_path = artifact_dir / "label_encoder.pkl"
    label_encoder = joblib.load(label_encoder_path)

    # 4) ëª¨ë¸ ê°€ì¤‘ì¹˜ (.pth)
    #    íŒŒì¼ëª…: spiking_tcn_<encoding_type>_best.pth
    encoding_type = emg_meta.get("encoding_type", "latency")
    model_path = artifact_dir / f"spiking_tcn_{encoding_type}_best.pth"
    state_dict = torch.load(model_path, map_location="cpu")

    return emg_meta, scaler, label_encoder, state_dict


def build_model_from_meta(emg_meta, state_dict):
    """emg_meta ì •ë³´ë¥¼ ì´ìš©í•´ SpikingTCN ëª¨ë¸ êµ¬ì¡° ìƒì„± + weight ë¡œë“œ"""

    num_inputs = int(emg_meta["num_channels"])
    num_classes = int(emg_meta["num_classes"])
    num_steps = int(emg_meta["num_steps"])

    model = SpikingTCN(
        num_inputs=num_inputs,
        num_channels=SPIKING_TCN_CHANNELS,
        num_classes=num_classes,
        kernel_size=SPIKING_TCN_KERNEL_SIZE,
        dropout=SPIKING_TCN_DROPOUT,
        timesteps=num_steps,
        beta=SPIKING_TCN_BETA,
        v_th=SPIKING_TCN_V_TH,
    )

    model.load_state_dict(state_dict)
    model.eval()
    return model


def preprocess_emg_window(emg_window: np.ndarray, scaler, emg_meta):
    """
    EMG ìœˆë„ìš° í•˜ë‚˜ë¥¼ ë°›ì•„ì„œ:
      1) shape ì²´í¬
      2) z-score ì •ê·œí™”
      3) PyTorch tensor [1, T, C] ë¡œ ë³€í™˜
    """
    window_size = int(emg_meta["window_size"])
    num_channels = int(emg_meta["num_channels"])

    if emg_window.shape != (window_size, num_channels):
        raise ValueError(
            f"EMG window shape mismatch: expected ({window_size}, {num_channels}), "
            f"but got {emg_window.shape}"
        )

    # [T, C] â†’ [T*C, C] ê¼´ì€ ì´ë¯¸ [T, C]ë¼ì„œ ê·¸ëŒ€ë¡œ flatten í›„ scaler ì ìš©
    emg_flat = emg_window.reshape(-1, num_channels)
    emg_scaled_flat = scaler.transform(emg_flat)
    emg_scaled = emg_scaled_flat.reshape(1, window_size, num_channels)  # [1, T, C]

    emg_tensor = torch.from_numpy(emg_scaled.astype(np.float32))
    return emg_tensor


def run_inference(model, emg_tensor: torch.Tensor, label_encoder):
    """
    ë‹¨ì¼ EMG ìœˆë„ìš°ì— ëŒ€í•´ ì¶”ë¡  ìˆ˜í–‰:
      - logits â†’ softmax â†’ ìµœê³  í™•ë¥  í´ë˜ìŠ¤
      - í´ë˜ìŠ¤ ì¸ë±ìŠ¤ ë° ë¼ë²¨ ë¬¸ìì—´ ë°˜í™˜
    """
    with torch.no_grad():
        logits = model(emg_tensor)  # shape: [1, num_classes]
        probs = torch.softmax(logits, dim=-1)
        conf, pred_idx = torch.max(probs, dim=-1)

    pred_idx = int(pred_idx.item())
    conf = float(conf.item())

    pred_label = label_encoder.inverse_transform([pred_idx])[0]
    return pred_idx, pred_label, conf, probs.numpy().squeeze()


def parse_args():
    parser = argparse.ArgumentParser(description="SpikingTCN EMG Inference Script")

    parser.add_argument(
        "--artifact-dir",
        type=str,
        required=True,
        help="Directory containing .pth, scaler, label_encoder, emg_meta.json",
    )
    parser.add_argument(
        "--emg-npy",
        type=str,
        default=None,
        help="Optional path to .npy file with EMG window (shape: [window_size, num_channels])",
    )
    parser.add_argument(
        "--use-dummy",
        action="store_true",
        help="Use dummy random EMG window instead of loading from file",
    )
    parser.add_argument(
    "--sample-from-mat",
    type=str,
    default=None,
    help="Load EMG window from a .mat file (e.g., ./src/data/s2.mat)",
    )

    return parser.parse_args()

class ExportWrapper(nn.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model

    def forward(self, x):
        logits, _ = self.model(x, return_spikes=True)
        return logits


def main():
    args = parse_args()
    artifact_dir = Path(args.artifact_dir)
    sample_index = 1500
    emg_meta, scaler, label_encoder, state_dict = load_artifacts(artifact_dir)
    print(f"    - encoding_type: {emg_meta.get('encoding_type')}")
    print(f"    - window_size: {emg_meta.get('window_size')}")
    print(f"    - num_channels: {emg_meta.get('num_channels')}")
    print(f"    - num_classes: {emg_meta.get('num_classes')}")

    print("\n[2] Building SpikingTCN model...")
    model = build_model_from_meta(emg_meta, state_dict)
    print("    - Model ready (eval mode).")
    
    window_size = int(emg_meta["window_size"])
    num_channels = int(emg_meta["num_channels"])

    # 3-1) MAT íŒŒì¼ì—ì„œ window ì¶”ì¶œ
    if args.sample_from_mat is not None:
        print(f"\n[3] Loading EMG sample window from mat: {args.sample_from_mat}")

        # Raw load
        emg_raw, labels_raw = load_ninapro_data(args.sample_from_mat)
        print(f"    - raw EMG shape: {emg_raw.shape}")
        print(f"    - raw labels shape: {labels_raw.shape}")

        # Windowing (trainingê³¼ ë™ì¼)
        X_win, y_win = preprocess_data_for_networks(
            emg_raw,
            labels_raw,
            window_size=window_size,
            overlap=100,
        )
        print(f"    - Generated windows: {X_win.shape}")

        # ì²« ë²ˆì§¸ ìœˆë„ìš° ì‚¬ìš© (or index ë³€ê²½)
        emg_window = X_win[sample_index]
        true_label_raw = int(y_win[sample_index])
        print(f"    - Selected window[0], shape: {emg_window.shape}")
        

    # 3-2) NPY ë¡œë“œ
    elif args.emg_npy is not None:
        print(f"\n[3] Loading EMG window from file: {args.emg_npy}")
        emg_window = np.load(args.emg_npy)
        print(f"    - Loaded EMG shape: {emg_window.shape}")

    # 3-3) Dummy window
    else:
        print("\n[3] No EMG window provided.")
        print("    Using dummy EMG window for testing.")
        emg_window = np.random.randn(window_size, num_channels).astype(np.float32)
        print(f"    - Dummy EMG shape: {emg_window.shape}")

    # -------------------------------------------------
    # ì „ì²˜ë¦¬ + ì¶”ë¡ 
    # -------------------------------------------------
    print("\n[4] Preprocessing EMG window (scaling + tensor conversion)...")
    emg_tensor = preprocess_emg_window(emg_window, scaler, emg_meta)
    print(f"    - Tensor shape: {tuple(emg_tensor.shape)}  # [1, T, C]")

    print("\n[5] Running inference...")
    pred_idx, pred_label, conf, probs = run_inference(model, emg_tensor, label_encoder)

    print("\n[6] Result")
    print("    - Predicted class index :", pred_idx)
    print("    - Predicted label       :", pred_label)
    print(f"    - Confidence (softmax)  : {conf:.4f}")
    print("    - Probabilities         :", probs)
    

    # âœ… sample-from-mat ëª¨ë“œì¼ ë•Œë§Œ GT ë¹„êµ
    if true_label_raw is not None:
        # label_encoderëŠ” s1 ê¸°ì¤€ìœ¼ë¡œ fit ë˜ì–´ìˆì§€ë§Œ,
        # s2ë„ ê°™ì€ stimulus ID ìŠ¤í˜ì´ìŠ¤(0~17)ì´ë¯€ë¡œ ê°™ì€ ë§¤í•‘ ì‚¬ìš© ê°€ëŠ¥.
        true_idx = int(label_encoder.transform([true_label_raw])[0])
        is_correct = (pred_idx == true_idx)

        print("\n[7] Ground Truth Check")
        print("    - Ground truth class index    :", true_idx)
        print("    - Ground truth raw label      :", true_label_raw)
        print("    - Prediction matches GT?      :", is_correct)

    print("\n=== Inference complete ===")
    onnx_path = artifact_dir / "spiking_tcn_inference.onnx"
    
    print(f"Exporting to ONNX: {onnx_path}")
    model_export = ExportWrapper(model)
    torch.onnx.export(
        model_export,
        emg_tensor,
        onnx_path.as_posix(),
        export_params=True,
        opset_version=17,
        do_constant_folding=True,
        input_names=["emg"],
        output_names=["logits"],
        dynamic_axes={
            "emg": {0: "batch_size", 1: "time_steps"},
            "logits": {0: "batch_size"},
        },
    )
    print("âœ… ONNX export done:", onnx_path)


if __name__ == "__main__":
    main()
